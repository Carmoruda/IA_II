{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Self-Organising Maps\n",
    "## Preparación de entorno\n",
    "#### Instalar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "# from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as patches\n",
    "\n",
    "# Permite que los gráficos sean interactivos en el notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset que se va a utilizar para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estructura -> minimo, maximo, (numero de colores por dato, numero de datos))\n",
    "datos = np.random.randint(0, 256, (3, 100))\n",
    "\"\"\"Matriz de 100 colores con 3 valores RGB aleatorios\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Setup\n",
    "#### Variables definidas por el alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lado_mapa = 100\n",
    "\"\"\"Tamaño del mapa de Kohonen (lado_mapa x lado_mapa)\"\"\"\n",
    "\n",
    "periodo = 5000\n",
    "\"\"\"Número total de iteraciones del entrenamiento\"\"\"\n",
    "\n",
    "learning_rate = 0.5\n",
    "\"\"\"Tasa de aprendizaje inicial (cuanto se modifica el peso en cada iteración)\"\"\"\n",
    "\n",
    "normalizar_datos = True\n",
    "\"\"\"Indica si hay que normalizar los datos o no\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir de este punto solo hay cálculos. No se introducen más valores \"a mano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_entradas = 3\n",
    "\"\"\"Dimensionalidad de los datos de entrada (3 para RGB)\"\"\"\n",
    "\n",
    "num_datos = 100\n",
    "\"\"\"Cantidad de muestras de colores que usaremos para entrenar el SOM\"\"\"\n",
    "\n",
    "vecindario = lado_mapa // 2\n",
    "\"\"\"Radio de influenia alrededor de la neurona ganadora\"\"\"\n",
    "\n",
    "if normalizar_datos:\n",
    "    # Escalamos los datos al rango [0, 1]\n",
    "    datos = datos / np.max(datos)\n",
    "\n",
    "matriz_pesos = np.random.random(lado_mapa, lado_mapa, num_entradas)\n",
    "\"\"\"Matriz de pesos de las neuronas\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones para entrenar/clasificar\n",
    "##### Distancia euclídea\n",
    "\n",
    "La distancia euclídea se define como la raíz cuadrada de la suma de las diferencias al cuadrado de cada componente de los vectores. Tenemos que calcularlo para vectores RGB, por lo que la fórmula es la siguiente:\n",
    "$$\\text{distancia euclídea} = \\sqrt{(R_{entrada} - R_{actual})^2 + (G_{entrada} - G_{actual})^2 + (B_{entrada} - B_{actual})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_bmu(patron_entrada, matriz_pesos, num_entradas) -> tuple:\n",
    "   \"\"\"Encuentra la BMU (neurona ganadora) para un patrón de entrada.\n",
    "\n",
    "   Args:\n",
    "      patron_entrada: Vector de entrada de color RGB normalizado\n",
    "      matriz_pesos: Matriz de pesos de las neuronas del SOM\n",
    "      num_entradas: Dimensionalidad de los datos de entrada (3 para RGB)\n",
    "\n",
    "   Returns:\n",
    "      tuple (bmu, bmu_idx):\n",
    "         - bmu: vector de pesos de la neurona ganadora\n",
    "         - bmu_idx: coordenadas [x,y] de la neurona ganadora\n",
    "   \"\"\"\n",
    "\n",
    "   distancia_minima = float('inf')\n",
    "   bmu = np.zeros(num_entradas)\n",
    "   bmu_idx = np.zeros(2)\n",
    "\n",
    "   # Recorremos cada neurona para encontrar la BMU\n",
    "   # Filas -> matriz_pesos.shape[0]\n",
    "   # Columnas -> matriz_pesos.shape[1]\n",
    "   for fila in range(matriz_pesos.shape[0]):\n",
    "      for columna in range(matriz_pesos.shape[1]):\n",
    "         peso_actual = matriz_pesos[fila, columna]\n",
    "\n",
    "         # Calculamos la distancia euclídea entre el peso actual y el patrón de entrada\n",
    "         distancia = np.linalg.norm(patron_entrada - peso_actual)\n",
    "\n",
    "         if distancia < distancia_minima:\n",
    "            distancia_minima = distancia\n",
    "            bmu = peso_actual\n",
    "            bmu_idx = np.array([fila, columna])\n",
    "\n",
    "   return bmu, bmu_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Rate\n",
    "\n",
    "El learning rate es un valor que se va reduciendo a medida que se va entrenando la red. Controla cuánto se modifican los pesos y determina el temaño del ajuste en los pesos de las neuronas. Se calcula usando una función de decaimiento exponencial:\n",
    "$$\\alpha(t) = \\alpha_0 \\cdot e^{-\\frac{t}{T}}$$\n",
    "\n",
    "Donde:\n",
    "* $\\alpha_0$: Learning rate inicial.\n",
    "* $t$: Iteración actual.\n",
    "* $T$: Número total de iteraciones.\n",
    "* $\\alpha(t)$: Learning rate en la iteración $t$.\n",
    "\n",
    "¿Porque usamos el decaimiento exponencial?:\n",
    "1. **Fase inicial:**\n",
    "   * Learning rate alto\n",
    "   * Nos permite hacer cambios grandes en los pesos\n",
    "   * Ayuda a la exploración inicial del espacio de colores\n",
    "2. **Fase media:**\n",
    "    * Learning rate decrece moderadamente\n",
    "    * Ajustes más refinados\n",
    "    * Mejor organización topológica\n",
    "3. **Fase final:**\n",
    "   * Learning rate muy pequeño\n",
    "   * Ajustes muy finos\n",
    "   * Estabilización del mapa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variacion_learning_rate(learning_rate_inicial, iteracion_actual, num_iteraciones) -> float:\n",
    "   \"\"\"Calcula el Learning Rate (eta) para  la iteración actual.\n",
    "\n",
    "   Args:\n",
    "      learning_rate_inicial: Learning rate inicial\n",
    "      iteracion_actual: Iteración actual\n",
    "      num_iteraciones: Número total de iteraciones\n",
    "\n",
    "   Returns:\n",
    "      float: Learning rate actualizado para la iteración actual\n",
    "   \"\"\"\n",
    "\n",
    "   return learning_rate_inicial * np.exp(-iteracion_actual / num_iteraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vecindario\n",
    "\n",
    "El vencindario es una región de influencia alrededor de la neurona ganadora que determina qué otrsa neuronas se actualizarán y en que medida. Es como una zona de impacto y también se calcula usando la función de decaimiento exponencial:\n",
    "$$\\sigma(t) = \\sigma_0 \\cdot e^{-\\frac{t}{T}}$$\n",
    "\n",
    "Donde:\n",
    "* $\\sigma_0$: Radio inicial del vecindario.\n",
    "* $t$: Iteración actual.\n",
    "* $T$: Número total de iteraciones.\n",
    "* $\\sigma(t)$: Radio del venciandario en la iteración $t$.\n",
    "\n",
    "¿Porque usamos el decaimiento exponencial?:\n",
    "1. **Fase inicial:**\n",
    "   * Vecindario grande\n",
    "   * Afecta a muchas neuronas vecinas\n",
    "   * Organiza global del mapa de Kohonen\n",
    "2. **Fase media:**\n",
    "    * Vecindario se va reduciendo gradualmente\n",
    "    * Afecta a menos neuronas\n",
    "    * Refina la organización topológica del mapa de Kohonen\n",
    "3. **Fase final:**\n",
    "   * Vecindario muy pequeño\n",
    "   * Solo afecta a la neurona ganadora y sus vecinas inmediatas\n",
    "   * Ajustes concretos localizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variacion_vecindario(vecindario_inicial, iteracion_actual, num_iteraciones) -> float:\n",
    "   \"\"\"Calcula el radio del vecindario para la iteración actual.\n",
    "\n",
    "   Args:\n",
    "      vecindario_inicial: Radio inicial del vecindario\n",
    "      iteracion_actual: Iteración actual\n",
    "      num_iteraciones: Número total de iteraciones\n",
    "\n",
    "   Returns:\n",
    "      float: Vecindario actualizado para la iteración actual\n",
    "   \"\"\"\n",
    "\n",
    "   return vecindario_inicial * np.exp(-iteracion_actual / num_iteraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decay (Amortiguación)\n",
    "\n",
    "El decay es una función que determina cómo se amortigua el learning rate según la distancia entre una neurona y la BMU (neurona ganadora). Se calcula usando una función gaussiana:\n",
    "\n",
    "$$h(d,\\sigma) = e^{-\\frac{d^2}{2\\sigma^2}}$$\n",
    "\n",
    "Donde:\n",
    "* $d$: Distancia entre la neurona y la BMU\n",
    "* $\\sigma$: Radio actual del vecindario\n",
    "* $h(d,\\sigma)$: Factor de amortiguación\n",
    "\n",
    "¿Por qué usamos una función gaussiana?:\n",
    "1. **Centro (BMU)**:\n",
    "   * Distancia = 0\n",
    "   * Máxima influencia ($\\approx 1$)\n",
    "   * Mayor ajuste de pesos\n",
    "\n",
    "2. **Neuronas cercanas**:\n",
    "   * Distancia pequeña\n",
    "   * Influencia moderada\n",
    "   * Ajuste proporcional a la cercanía\n",
    "\n",
    "3. **Neuronas lejanas**:\n",
    "   * Distancia grande\n",
    "   * Influencia mínima ($\\approx 0$)\n",
    "   * Casi no se modifican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decay(distancia_BMU, vecindario_actual) -> float:\n",
    "   \"\"\"Calcula la amortiguación de eta en función de la distancia en el mapa entre una neurona y la BMU.\n",
    "\n",
    "   Args:\n",
    "      distancia_BMU: Distancia entre la neurona y la BMU\n",
    "      vecindario_actual: Radio actual del vecindario\n",
    "\n",
    "   Returns:\n",
    "      float: Factor de amortiguación para la iteración (Está entre 0 y 1)\n",
    "   \"\"\"\n",
    "   return np.exp(-distancia_BMU / (2 * (vecindario_actual**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones para dibujar la salida de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pintar_mapa(matriz_valores):\n",
    "    \"\"\"Función para pintar una matriz de valores como colores RGB.\n",
    "    Visualiza el mapa de Kohonen, donde cada neurona se representa como un rectángulo de color RGB.\n",
    "\n",
    "    Args:\n",
    "        matriz_valores: Matriz de valores RGB (lado_mapa x lado_mapa x 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # Creamos una nueva figura\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Establecemos los ejes\n",
    "    ax = fig.add_subplot(111, aspect='equal') # aspect='equal' mantiene cuadrados los rectángulos\n",
    "    ax.set_xlim((0, matriz_pesos.shape[0]+1)) # Limites del eje x\n",
    "    ax.set_ylim((0, matriz_pesos.shape[1]+1)) # Limites del eje y\n",
    "    ax.set_title('Self-Organising Map después de %d iteraciones' % periodo)\n",
    "\n",
    "    # Dibujamos los rectángulos por cada neurona (Un cuadrado RGB)\n",
    "    for fila in range(1, matriz_valores.shape[0] + 1):\n",
    "        for columna in range(1, matriz_valores.shape[1] + 1):\n",
    "            ax.add_patch(patches.Rectangle(\n",
    "                (fila - 0.5, columna - 0.5),                           # Posición (x,y) del rectángulo\n",
    "                1, 1,                                                  # Ancho y alto del rectángulo\n",
    "                facecolor = matriz_valores[fila - 1, columna - 1, :],  # Color RGB del rectángulo\n",
    "                edgecolor = 'none'                                     # Sin borde\n",
    "            ))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrena la red con el dataset de entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clasifica los patrones de entrenamiento con la matriz de pesos recién entrenada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clasifica nuevos patrones\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
